{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNMpK3/VZqCdxOtfzfW1VWl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manisshapande/llm_engineering/blob/main/CompanyBrochure.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Company Brochure ##\n"
      ],
      "metadata": {
        "id": "doGGIUyh8I5h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2BE2hHFE7MNb"
      },
      "outputs": [],
      "source": [
        "#Imports\n",
        "import os\n",
        "import requests\n",
        "import json\n",
        "from typing import List\n",
        "from dotenv import load_dotenv\n",
        "from bs4 import BeautifulSoup\n",
        "from IPython.display import Markdown, display, update_display\n",
        "from openai import OpenAI\n",
        "\n",
        "import ollama"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Setting Models\n",
        "MODEL_LLAMA = 'llama3.2'\n",
        "MODEL = 'gpt-40-mini'"
      ],
      "metadata": {
        "id": "IZnV6_K4_scv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Setting function with get links\n",
        "\n",
        "class Website:\n",
        "    def __init__(self, url):\n",
        "        self.url = url\n",
        "        response = requests.get(url)\n",
        "        self.body = response.content\n",
        "        soup = BeautifulSoup(self.body, 'html.parser')\n",
        "        self.title = soup.title.string if soup.title else \"No title found\"\n",
        "        if soup.body:\n",
        "            for irrevalant in soup.body([\"script\",\"style\",\"img\",\"input\"]):\n",
        "                irrevalant.decompose()\n",
        "            self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
        "        else:\n",
        "            self.text = \"\"\n",
        "        links = [link.get('href') for link in soup.find_all('a')]\n",
        "        self.links = [link for link in links if link]\n",
        "\n",
        "    def get_contents(self):\n",
        "        return f\"Webpage Title: \\n{self.title}\\nWebpage Contents: \\n{self.text}\\n\\n\"\n",
        ""
      ],
      "metadata": {
        "id": "60EXxPHi_5OT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#extraxt links from any website page\n",
        "\n",
        "pg = Website(\"https://anthropic.com\")\n",
        "pg.links"
      ],
      "metadata": {
        "id": "UQDUHgBVAIXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setting prompts\n",
        "\n",
        "link_system_prompt = \"You are provided with a list of links found on a webpage. \\\n",
        "You are able to decide which of the links would be most relevant to include in a brochure about the company, \\\n",
        "such as links to an About page, or a Company page, or Careers/Jobs pages.\\n\"\n",
        "link_system_prompt += \"You should respond in JSON as in this example:\"\n",
        "link_system_prompt += \"\"\"\n",
        "{\n",
        "    \"links\": [\n",
        "        {\"type\": \"about page\", \"url\": \"https://full.url/goes/here/about\"},\n",
        "        {\"type\": \"careers page\": \"url\": \"https://another.full.url/careers\"}\n",
        "    ]\n",
        "}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "UueCOpHcAjO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print to check\n",
        "print(link_system_prompt)"
      ],
      "metadata": {
        "id": "_gY5dIf7AsCl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get links with user prompt\n",
        "\n",
        "def get_links_user_prompt(website):\n",
        "    user_prompt = f\"Here is the list of links on the website of {website.url} - \"\n",
        "    user_prompt += \"please decide which of these are relevant web links for a brochure about the company, respond with the full https URL in JSON format. \\\n",
        "Do not include Terms of Service, Privacy, email links.\\n\"\n",
        "    user_prompt += \"Links (some might be relative links):\\n\"\n",
        "    user_prompt += \"\\n\".join(website.links)\n",
        "    return user_prompt"
      ],
      "metadata": {
        "id": "9o8P5sb4AvIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print to check\n",
        "print(get_links_user_prompt(pg))"
      ],
      "metadata": {
        "id": "hOB39qWqA64l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get Llama 3.2 to answer\n",
        "def get_links(url):\n",
        "    website = Website(url)\n",
        "    response = ollama.chat(\n",
        "        model=MODEL_LLAMA,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": link_system_prompt},\n",
        "            {\"role\": \"user\", \"content\": get_links_user_prompt(website)}\n",
        "        ]\n",
        "    )\n",
        "    result = response['message']['content']\n",
        "    print(f\"About to parse this into json: {result}\")\n",
        "    return json.loads(result)"
      ],
      "metadata": {
        "id": "13oWk53zBE86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get Chapgpt to answer\n",
        "def get_links_gpt(url):\n",
        "    website = Website(url)\n",
        "    response = openai.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": link_system_prompt},\n",
        "            {\"role\": \"user\", \"content\": get_links_user_prompt(website)}\n",
        "        ],\n",
        "    response_format={\"type\": \"json_object\"}\n",
        "    )\n",
        "    result = response.choices[0].message.content\n",
        "    return json.loads(result)"
      ],
      "metadata": {
        "id": "vzEx5TDuBGop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anthropic = Website(\"https://anthropic.com\")\n",
        "anthropic.links"
      ],
      "metadata": {
        "id": "ZkslLAFiBavN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_links(\"https://anthropic.com\")"
      ],
      "metadata": {
        "id": "6zGmSkwHBbfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Within the main url you get links . retrieve all links and its contents\n",
        "def get_all_details(url):\n",
        "    result = \"Landing Page:\\n\"\n",
        "    result += Website(url).get_contents()\n",
        "    result += Website(url).get_contents()\n",
        "    links = get_links(url)\n",
        "    print(\"Found links:\", links)\n",
        "    for link in links[\"links\"]:\n",
        "        result +=f\"\\n\\n{link['type']}\\n\"\n",
        "        result +=Website(link[\"url\"]).get_contents()\n",
        "    return result"
      ],
      "metadata": {
        "id": "vTg39sssBhbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(get_all_details(\"https://anthropic.com\"))"
      ],
      "metadata": {
        "id": "4Dwd6UkUBtMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Set system prompt\n",
        "system_prompt = \"You are an assistant that analyzes the contents of several relevant pages from a company website \\\n",
        "and creates a short brochure about the company for prospective customers, investors and recruits. Respond in markdown.\\\n",
        "Include details of company culture, customers and careers/jobs if you have the information.\"\n",
        "\n",
        "# Or uncomment the lines below for a more humorous brochure - this demonstrates how easy it is to incorporate 'tone':\n",
        "\n",
        "# system_prompt = \"You are an assistant that analyzes the contents of several relevant pages from a company website \\\n",
        "# and creates a short humorous, entertaining, jokey brochure about the company for prospective customers, investors and recruits. Respond in markdown.\\\n",
        "# Include details of company culture, customers and careers/jobs if you have the information.\""
      ],
      "metadata": {
        "id": "vhmRMlhrBt_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get brochure\n",
        "\n",
        "def get_brochure_user_prompt(company_name, url):\n",
        "    user_prompt = f\"You are looking at a company called: {company_name}\\n\"\n",
        "    user_prompt += f\"Here are the contents of its landing page and other relevant pages; use this information to build a short brochure of the company in markdown.\\n\"\n",
        "    user_prompt += get_all_details(url)\n",
        "    user_prompt = user_prompt[:20_000] # Truncate if more than 20,000 characters\n",
        "    return user_prompt"
      ],
      "metadata": {
        "id": "_DbUHHZoB9QX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_brochure_user_prompt(\"Anthropic\", \"https://anthropic.com\")"
      ],
      "metadata": {
        "id": "6DfLxRBeCDrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def create_brochure(company_name, url):\n",
        "#     response = openai.chat.completions.create(\n",
        "#         model=MODEL,\n",
        "#         messages=[\n",
        "#             {\"role\": \"system\", \"content\": system_prompt},\n",
        "#             {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n",
        "#           ],\n",
        "#     )\n",
        "#     result = response.choices[0].message.content\n",
        "#     display(Markdown(result))\n",
        "\n",
        "def create_brochure(company_name, url):\n",
        "    response = ollama.chat(\n",
        "        model=MODEL_LLAMA,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n",
        "        ]\n",
        "    )\n",
        "    result = response['message']['content']\n",
        "    display(Markdown(result))"
      ],
      "metadata": {
        "id": "_DsgYBWPCMJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_brochure(\"Anthropic\", \"https://anthropic.com\")"
      ],
      "metadata": {
        "id": "MSTWJEdCCQtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def stream_brochure(company_name, url):\n",
        "#     stream = openai.chat.completions.create(\n",
        "#         model=MODEL,\n",
        "#         messages=[\n",
        "#             {\"role\": \"system\", \"content\": system_prompt},\n",
        "#             {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n",
        "#           ],\n",
        "#         stream=True\n",
        "#     )\n",
        "\n",
        "# # For just a simple output you can do the following two lines;\n",
        "# # for chunk in stream:\n",
        "# #    print(chunk.choices[0].delta.content or '',end='')\n",
        "\n",
        "#     response = \"\"\n",
        "#     display_handle = display(Markdown(\"\"), display_id=True)\n",
        "#     for chunk in stream:\n",
        "#         response += chunk.choices[0].delta.content or ''\n",
        "#         response = response.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
        "#         update_display(Markdown(response), display_id=display_handle.display_id)\n",
        "\n",
        "def stream_brochure(company_name, url):\n",
        "    stream = ollama.chat(\n",
        "        model=MODEL_LLAMA,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n",
        "        ],\n",
        "        stream=True\n",
        "    )\n",
        "\n",
        "    # For just a simple output you can do the following two lines;\n",
        "    # for chunk in stream:\n",
        "    #    print(chunk['message']['content'] or '', end='')\n",
        "\n",
        "    response = \"\"\n",
        "    display_handle = display(Markdown(\"\"), display_id=True)\n",
        "    for chunk in stream:\n",
        "        response += chunk['message']['content'] or ''\n",
        "        response = response.replace(\"```\", \"\").replace(\"markdown\", \"\")\n",
        "        update_display(Markdown(response), display_id=display_handle.display_id)\n"
      ],
      "metadata": {
        "id": "nqjzi7jhCR2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stream_brochure(\"Anthropic\", \"https://anthropic.com\")"
      ],
      "metadata": {
        "id": "ePpcw2q6CYyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try changing the system prompt to the humorous version when you make the Brochure for Hugging Face:\n",
        "\n",
        "stream_brochure(\"HuggingFace\", \"https://huggingface.co\")"
      ],
      "metadata": {
        "id": "jM1Ot73CCfTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_llama_response_basic(company_name, url):\n",
        "    try:\n",
        "        response = ollama.chat(\n",
        "            model=MODEL_LLAMA,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_prompt},\n",
        "                {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # Print the entire raw response for debugging purposes\n",
        "        print(\"Raw response received:\", response)\n",
        "\n",
        "        # Check if the response contains 'message' and 'content'\n",
        "        if 'message' in response and 'content' in response['message']:\n",
        "            response_content = response['message']['content']\n",
        "            print(\"Content from response:\", response_content)\n",
        "            return response_content\n",
        "        else:\n",
        "            print(\"Response does not contain expected 'message' or 'content'\")\n",
        "            return response\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return {}\n",
        "\n",
        "# Example usage\n",
        "test_llama_response_basic(\"HuggingFace\", \"https://huggingface.co\")\n"
      ],
      "metadata": {
        "id": "ZmsEFFMuCnPR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}